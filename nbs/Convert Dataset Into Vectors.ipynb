{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed1e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "BASE_DIR = pathlib.Path().resolve().parent\n",
    "DATASET_DIR = BASE_DIR / \"datasets\"\n",
    "RAW_DATA_DIR = DATASET_DIR / \"raw-data\"\n",
    "EXPORT_DIR = DATASET_DIR / \"exports\"\n",
    "EXPORT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "PHISHING_DATASET_PATH = EXPORT_DIR / \"phishing-dataset.csv\"\n",
    "\n",
    "METADATA_EXPORT_PATH = EXPORT_DIR / 'phishing-metadata.pkl'\n",
    "TOKENIZER_EXPORT_PATH = EXPORT_DIR / 'phishing-tokenizer.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0f79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PHISHING_DATASET_PATH)\n",
    "df.text = df.text.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f9395d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phishing</td>\n",
       "      <td>onlineservice@nafcu.org Account Notification:Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phishing</td>\n",
       "      <td>mis@bsch.es Banca Personal Estimados clientes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phishing</td>\n",
       "      <td>technical_department-id-708ziy@bbandt.com BB&amp;T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phishing</td>\n",
       "      <td>customer_service@paypal.com Notification of Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phishing</td>\n",
       "      <td>customer_service@paypal.com Notification of Li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  phishing  onlineservice@nafcu.org Account Notification:Y...\n",
       "1  phishing  mis@bsch.es Banca Personal Estimados clientes,...\n",
       "2  phishing  technical_department-id-708ziy@bbandt.com BB&T...\n",
       "3  phishing  customer_service@paypal.com Notification of Li...\n",
       "4  phishing  customer_service@paypal.com Notification of Li..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a87fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label'].tolist()\n",
    "texts = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0638dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ham',\n",
       " \"rosehannah@yahoo.com For real when u getting on yo? I only need 2 more tickets and one more jacket and I'm done. I already used all my multis.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[2350], texts[2350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c047b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'ham', '1': 'phishing'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_legend = {\"ham\": 0, \"phishing\": 1}\n",
    "label_legend_inverted = {f\"{v}\": k for k,v in label_legend.items()}\n",
    "label_legend_inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72e5f1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_as_int = [label_legend[x] for x in labels]\n",
    "labels_as_int[2350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "114a9089",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.randint(0, len(labels))\n",
    "\n",
    "assert texts[random_idx] == df.iloc[random_idx].text\n",
    "\n",
    "assert labels[random_idx] == df.iloc[random_idx].label\n",
    "\n",
    "assert label_legend_inverted[str(labels_as_int[random_idx])] == df.iloc[random_idx].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc8f804",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9997ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45006ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mTokenizer\u001b[49m(num_words\u001b[38;5;241m=\u001b[39mMAX_NUM_WORDS)\n\u001b[0;32m      2\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mfit_on_texts(texts)\n\u001b[0;32m      3\u001b[0m sequences \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(texts)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1735f148",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m word_index \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mword_index\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "963d19ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd76962",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ee03eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af87b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  45, 103, 107],\n",
       "       [  0,   0,   0, ..., 432, 189,  16],\n",
       "       [  0,   0,   0, ...,  45, 103, 107],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 100,  87, 105],\n",
       "       [  0,   0,   0, ...,   8,  22, 146],\n",
       "       [  0,   0,   0, ...,  87, 346, 105]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ff31344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70904c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_as_int_array = np.asarray(labels_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e10152e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_as_int_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2289128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels_as_int_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23c01b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22331d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\bachi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bachi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\bachi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\bachi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\bachi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.23.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Bachi\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1c68fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff810d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "514301da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f1dc006",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {\n",
    "    \"X_train\": X_train,\n",
    "    \"X_test\": X_test,\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "    \"max_words\": MAX_NUM_WORDS,\n",
    "    \"max_seq_length\": MAX_SEQUENCE_LENGTH,\n",
    "    \"legend\": label_legend,\n",
    "    \"legend_inverted\": label_legend_inverted,\n",
    "    \"tokenizer\": tokenizer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85392fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(METADATA_EXPORT_PATH, 'wb') as f:\n",
    "    pickle.dump(training_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e34b92f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRAINING_DATA_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mTRAINING_DATA_PATH\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TRAINING_DATA_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "with open(TRAINING_DATA_PATH, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6cd017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
